{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ddea62f9",
   "metadata": {},
   "source": [
    "# Advanced Differential Equations in Deep Learning for Robot Control\n",
    "\n",
    "### Author: Dr. D Bhanu Prakash\n",
    "\n",
    "This comprehensive implementation covers:\n",
    "1. Neural ODEs with advanced solvers (RK45, Dopri5)\n",
    "2. Stochastic Differential Equations (SDEs) with noise modeling\n",
    "3. Robot control applications (pendulum, manipulator)\n",
    "4. Model Predictive Control with Neural DEs\n",
    "5. Detailed mathematical explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258e6687",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Mathematical Foundation:\n",
    "-----------------------\n",
    "\n",
    "1. NEURAL ORDINARY DIFFERENTIAL EQUATIONS (Neural ODE):\n",
    "   \n",
    "   Standard ODE: dz/dt = f(z(t), t, θ)\n",
    "   \n",
    "   Where:\n",
    "   - z(t) ∈ ℝⁿ is the state at time t\n",
    "   - f is a neural network with parameters θ\n",
    "   - We solve: z(t₁) = z(t₀) + ∫[t₀,t₁] f(z(t), t, θ) dt\n",
    "   \n",
    "   Key insight: Instead of discrete layers, we have continuous transformations\n",
    "   \n",
    "   Adjoint Method for Training:\n",
    "   - Forward: Solve ODE to get z(t₁)\n",
    "   - Backward: Solve augmented ODE backwards in time\n",
    "   - Adjoint state: a(t) = ∂L/∂z(t)\n",
    "   - da/dt = -a(t)ᵀ ∂f/∂z\n",
    "   - This saves memory - O(1) instead of O(depth)\n",
    "\n",
    "2. STOCHASTIC DIFFERENTIAL EQUATIONS (SDE):\n",
    "   \n",
    "   General SDE: dz = f(z,t)dt + g(z,t)dW\n",
    "   \n",
    "   Where:\n",
    "   - f(z,t) is the drift term (deterministic)\n",
    "   - g(z,t) is the diffusion term (stochastic)\n",
    "   - dW is Wiener process (Brownian motion): dW ~ N(0, dt)\n",
    "   \n",
    "   Euler-Maruyama discretization:\n",
    "   z(t+Δt) = z(t) + f(z,t)Δt + g(z,t)√(Δt)ε, where ε ~ N(0,I)\n",
    "   \n",
    "   Why SDEs?\n",
    "   - Model uncertainty in dynamics\n",
    "   - Robust to perturbations\n",
    "   - Better generalization\n",
    "\n",
    "3. ROBOT DYNAMICS:\n",
    "   \n",
    "   General form: M(q)q̈ + C(q,q̇)q̇ + G(q) = τ\n",
    "   \n",
    "   Where:\n",
    "   - q: joint angles (configuration)\n",
    "   - q̇: joint velocities\n",
    "   - q̈: joint accelerations\n",
    "   - M(q): inertia matrix\n",
    "   - C(q,q̇): Coriolis and centrifugal terms\n",
    "   - G(q): gravity term\n",
    "   - τ: control torques\n",
    "   \n",
    "   State-space form:\n",
    "   x = [q, q̇]ᵀ\n",
    "   dx/dt = [q̇, M⁻¹(τ - C(q,q̇)q̇ - G(q))]ᵀ\n",
    "\n",
    "4. MODEL PREDICTIVE CONTROL (MPC) with Neural ODE:\n",
    "   \n",
    "   Optimization problem:\n",
    "   min ∑ᵢ [‖z(tᵢ) - z_ref(tᵢ)‖² + λ‖u(tᵢ)‖²]\n",
    "   \n",
    "   subject to: dz/dt = f_neural(z,u,t)\n",
    "               u_min ≤ u ≤ u_max\n",
    "   \n",
    "   Where:\n",
    "   - z_ref is reference trajectory\n",
    "   - u is control input\n",
    "   - λ is control cost weight\n",
    "\n",
    "Dependencies: pip install torch numpy matplotlib scipy\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b26f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from scipy.integrate import odeint\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a512ec18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# PART 1: ADVANCED ODE SOLVERS\n",
    "# ============================================================================\n",
    "\n",
    "class RK45Solver:\n",
    "    \"\"\"\n",
    "    Runge-Kutta 4/5 adaptive step size solver\n",
    "    \n",
    "    Mathematical Details:\n",
    "    --------------------\n",
    "    Uses Dormand-Prince method with error estimation:\n",
    "    \n",
    "    k₁ = f(t, y)\n",
    "    k₂ = f(t + c₂h, y + h(a₂₁k₁))\n",
    "    ...\n",
    "    k₆ = f(t + c₆h, y + h(a₆₁k₁ + ... + a₆₅k₅))\n",
    "    \n",
    "    Fifth-order solution:\n",
    "    y_{n+1} = yₙ + h(b₁k₁ + b₂k₂ + ... + b₆k₆)\n",
    "    \n",
    "    Fourth-order solution (for error):\n",
    "    ŷ_{n+1} = yₙ + h(b̂₁k₁ + b̂₂k₂ + ... + b̂₆k₆)\n",
    "    \n",
    "    Error estimate: e = ‖y_{n+1} - ŷ_{n+1}‖\n",
    "    \n",
    "    Adaptive step: h_new = 0.9 * h * (tol/e)^(1/5)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, func, rtol=1e-3, atol=1e-6):\n",
    "        self.func = func\n",
    "        self.rtol = rtol\n",
    "        self.atol = atol\n",
    "        \n",
    "        # Dormand-Prince coefficients\n",
    "        self.c = torch.tensor([0., 1./5, 3./10, 4./5, 8./9, 1.])\n",
    "        self.a = [\n",
    "            [],\n",
    "            [1./5],\n",
    "            [3./40, 9./40],\n",
    "            [44./45, -56./15, 32./9],\n",
    "            [19372./6561, -25360./2187, 64448./6561, -212./729],\n",
    "            [9017./3168, -355./33, 46732./5247, 49./176, -5103./18656]\n",
    "        ]\n",
    "        self.b = torch.tensor([35./384, 0., 500./1113, 125./192, -2187./6784, 11./84])\n",
    "        self.b_hat = torch.tensor([5179./57600, 0., 7571./16695, 393./640, -92097./339200, 187./2100, 1./40])\n",
    "    \n",
    "    def step(self, t, y, h):\n",
    "        \"\"\"Single RK45 step with error estimation\"\"\"\n",
    "        k = []\n",
    "        k.append(self.func(t, y))\n",
    "        \n",
    "        for i in range(1, 6):\n",
    "            t_i = t + self.c[i] * h\n",
    "            y_i = y.clone()\n",
    "            for j, a_ij in enumerate(self.a[i]):\n",
    "                y_i = y_i + h * a_ij * k[j]\n",
    "            k.append(self.func(t_i, y_i))\n",
    "        \n",
    "        # Fifth-order solution\n",
    "        y_new = y.clone()\n",
    "        for i, b_i in enumerate(self.b):\n",
    "            y_new = y_new + h * b_i * k[i]\n",
    "        \n",
    "        # Fourth-order solution for error estimate\n",
    "        y_hat = y.clone()\n",
    "        for i, b_hat_i in enumerate(self.b_hat):\n",
    "            y_hat = y_hat + h * b_hat_i * k[i]\n",
    "        \n",
    "        # Error estimate\n",
    "        error = torch.abs(y_new - y_hat).max()\n",
    "        \n",
    "        return y_new, error\n",
    "    \n",
    "    def integrate(self, y0, t_span, max_steps=1000):\n",
    "        \"\"\"Adaptive integration from t_span[0] to t_span[1]\"\"\"\n",
    "        t = t_span[0]\n",
    "        y = y0\n",
    "        h = 0.1  # initial step size\n",
    "        \n",
    "        trajectory = [y0.clone()]\n",
    "        times = [t]\n",
    "        \n",
    "        steps = 0\n",
    "        while t < t_span[1] and steps < max_steps:\n",
    "            # Adjust final step\n",
    "            if t + h > t_span[1]:\n",
    "                h = t_span[1] - t\n",
    "            \n",
    "            # Take step\n",
    "            y_new, error = self.step(t, y, h)\n",
    "            \n",
    "            # Compute tolerance\n",
    "            tol = self.atol + self.rtol * torch.abs(y).max()\n",
    "            \n",
    "            # Accept or reject step\n",
    "            if error < tol or h < 1e-8:\n",
    "                t += h\n",
    "                y = y_new\n",
    "                trajectory.append(y.clone())\n",
    "                times.append(t)\n",
    "                steps += 1\n",
    "            \n",
    "            # Adapt step size\n",
    "            if error > 0:\n",
    "                h = 0.9 * h * (tol / error) ** 0.2\n",
    "                h = min(h, 0.5)  # max step\n",
    "            \n",
    "        return torch.stack(trajectory), torch.tensor(times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37e42b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# PART 2: STOCHASTIC DIFFERENTIAL EQUATIONS (SDE)\n",
    "# ============================================================================\n",
    "\n",
    "class NeuralSDE(nn.Module):\n",
    "    \"\"\"\n",
    "    Neural Stochastic Differential Equation\n",
    "    \n",
    "    Mathematical Form:\n",
    "    -----------------\n",
    "    dz = f_drift(z, t, θ) dt + g_diffusion(z, t, θ) dW\n",
    "    \n",
    "    Where:\n",
    "    - f_drift: deterministic dynamics (neural network)\n",
    "    - g_diffusion: stochastic dynamics (neural network)\n",
    "    - dW: Wiener process increment\n",
    "    \n",
    "    Discretization (Euler-Maruyama):\n",
    "    z(t+Δt) = z(t) + f_drift(z,t)Δt + g_diffusion(z,t)√Δt·ε\n",
    "    where ε ~ N(0, I)\n",
    "    \n",
    "    Applications:\n",
    "    - Modeling uncertainty in robot dynamics\n",
    "    - Robust control under perturbations\n",
    "    - Learning stochastic processes\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, state_dim, hidden_dim=64, noise_type='diagonal'):\n",
    "        super().__init__()\n",
    "        self.state_dim = state_dim\n",
    "        self.noise_type = noise_type\n",
    "        \n",
    "        # Drift network: f_drift(z, t)\n",
    "        self.drift_net = nn.Sequential(\n",
    "            nn.Linear(state_dim + 1, hidden_dim),  # +1 for time\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_dim, state_dim)\n",
    "        )\n",
    "        \n",
    "        # Diffusion network: g_diffusion(z, t)\n",
    "        if noise_type == 'diagonal':\n",
    "            # Output diagonal elements: g(z,t) = diag(σ₁, σ₂, ..., σₙ)\n",
    "            self.diffusion_net = nn.Sequential(\n",
    "                nn.Linear(state_dim + 1, hidden_dim),\n",
    "                nn.Tanh(),\n",
    "                nn.Linear(hidden_dim, state_dim),\n",
    "                nn.Softplus()  # ensure positive\n",
    "            )\n",
    "        elif noise_type == 'general':\n",
    "            # Output full matrix: g(z,t) ∈ ℝⁿˣⁿ\n",
    "            self.diffusion_net = nn.Sequential(\n",
    "                nn.Linear(state_dim + 1, hidden_dim),\n",
    "                nn.Tanh(),\n",
    "                nn.Linear(hidden_dim, state_dim * state_dim)\n",
    "            )\n",
    "    \n",
    "    def drift(self, z, t):\n",
    "        \"\"\"Compute drift term f(z, t)\"\"\"\n",
    "        t_expand = t * torch.ones(z.shape[0], 1)\n",
    "        inp = torch.cat([z, t_expand], dim=1)\n",
    "        return self.drift_net(inp)\n",
    "    \n",
    "    def diffusion(self, z, t):\n",
    "        \"\"\"Compute diffusion term g(z, t)\"\"\"\n",
    "        t_expand = t * torch.ones(z.shape[0], 1)\n",
    "        inp = torch.cat([z, t_expand], dim=1)\n",
    "        \n",
    "        if self.noise_type == 'diagonal':\n",
    "            # Return diagonal matrix as vector\n",
    "            return self.diffusion_net(inp)\n",
    "        else:\n",
    "            # Return full matrix\n",
    "            g_flat = self.diffusion_net(inp)\n",
    "            return g_flat.reshape(-1, self.state_dim, self.state_dim)\n",
    "    \n",
    "    def forward(self, z0, t_span, dt=0.01, return_path=False):\n",
    "        \"\"\"\n",
    "        Integrate SDE using Euler-Maruyama method\n",
    "        \n",
    "        z(t+dt) = z(t) + f(z,t)dt + g(z,t)√dt·ε\n",
    "        \"\"\"\n",
    "        t = t_span[0]\n",
    "        z = z0\n",
    "        \n",
    "        if return_path:\n",
    "            trajectory = [z0.clone()]\n",
    "            times = [t]\n",
    "        \n",
    "        while t < t_span[1]:\n",
    "            dt_step = min(dt, t_span[1] - t)\n",
    "            \n",
    "            # Drift term\n",
    "            drift = self.drift(z, t)\n",
    "            \n",
    "            # Diffusion term\n",
    "            diffusion = self.diffusion(z, t)\n",
    "            \n",
    "            # Wiener process increment: dW ~ N(0, dt)\n",
    "            dW = torch.randn_like(z) * torch.sqrt(torch.tensor(dt_step))\n",
    "            \n",
    "            # Euler-Maruyama step\n",
    "            if self.noise_type == 'diagonal':\n",
    "                z = z + drift * dt_step + diffusion * dW\n",
    "            else:\n",
    "                # Matrix multiplication for general noise\n",
    "                z = z + drift * dt_step + torch.bmm(diffusion, dW.unsqueeze(-1)).squeeze(-1)\n",
    "            \n",
    "            t += dt_step\n",
    "            \n",
    "            if return_path:\n",
    "                trajectory.append(z.clone())\n",
    "                times.append(t)\n",
    "        \n",
    "        if return_path:\n",
    "            return torch.stack(trajectory), torch.tensor(times)\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41336e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# PART 3: ROBOT CONTROL - INVERTED PENDULUM\n",
    "# ============================================================================\n",
    "\n",
    "class PendulumDynamics:\n",
    "    \"\"\"\n",
    "    Inverted Pendulum Dynamics\n",
    "    \n",
    "    Mathematical Model:\n",
    "    ------------------\n",
    "    State: x = [θ, θ̇]ᵀ\n",
    "    - θ: angle from vertical (rad)\n",
    "    - θ̇: angular velocity (rad/s)\n",
    "    \n",
    "    Equation of motion:\n",
    "    θ̈ = (g/L)sin(θ) - (b/mL²)θ̇ + (1/mL²)τ\n",
    "    \n",
    "    Where:\n",
    "    - m: mass (kg)\n",
    "    - L: length (m)\n",
    "    - g: gravity (9.81 m/s²)\n",
    "    - b: damping coefficient\n",
    "    - τ: control torque (N·m)\n",
    "    \n",
    "    State-space form:\n",
    "    dx/dt = [θ̇, (g/L)sin(θ) - (b/mL²)θ̇ + (1/mL²)τ]ᵀ\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, mass=1.0, length=1.0, damping=0.1):\n",
    "        self.m = mass\n",
    "        self.L = length\n",
    "        self.b = damping\n",
    "        self.g = 9.81\n",
    "    \n",
    "    def dynamics(self, state, control):\n",
    "        \"\"\"\n",
    "        Compute dx/dt given state and control\n",
    "        \n",
    "        Args:\n",
    "            state: [batch, 2] - [θ, θ̇]\n",
    "            control: [batch, 1] - [τ]\n",
    "        \n",
    "        Returns:\n",
    "            [batch, 2] - [dθ/dt, dθ̇/dt]\n",
    "        \"\"\"\n",
    "        theta = state[:, 0:1]\n",
    "        theta_dot = state[:, 1:2]\n",
    "        \n",
    "        # θ̈ = (g/L)sin(θ) - (b/mL²)θ̇ + (1/mL²)τ\n",
    "        theta_ddot = (self.g / self.L) * torch.sin(theta) - \\\n",
    "                     (self.b / (self.m * self.L**2)) * theta_dot + \\\n",
    "                     (1.0 / (self.m * self.L**2)) * control\n",
    "        \n",
    "        return torch.cat([theta_dot, theta_ddot], dim=1)\n",
    "\n",
    "\n",
    "class NeuralControllerODE(nn.Module):\n",
    "    \"\"\"\n",
    "    Neural ODE-based controller for inverted pendulum\n",
    "    \n",
    "    Architecture:\n",
    "    ------------\n",
    "    1. State encoder: maps observations to latent space\n",
    "    2. Neural ODE: evolves latent state forward in time\n",
    "    3. Policy network: maps latent state to control action\n",
    "    \n",
    "    Training:\n",
    "    --------\n",
    "    - Minimize tracking error: L = Σ ‖θ(t) - θ_ref(t)‖²\n",
    "    - Control cost: + λ Σ ‖τ(t)‖²\n",
    "    - Energy efficiency: + γ Σ |θ̇(t)|\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, state_dim=2, latent_dim=8, hidden_dim=64):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.state_dim = state_dim\n",
    "        self.latent_dim = latent_dim\n",
    "        \n",
    "        # State encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(state_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, latent_dim)\n",
    "        )\n",
    "        \n",
    "        # Neural ODE function\n",
    "        self.ode_func = nn.Sequential(\n",
    "            nn.Linear(latent_dim + 1, hidden_dim),  # +1 for time\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_dim, latent_dim)\n",
    "        )\n",
    "        \n",
    "        # Policy network (outputs control)\n",
    "        self.policy = nn.Sequential(\n",
    "            nn.Linear(latent_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, 1),\n",
    "            nn.Tanh()  # bounded control\n",
    "        )\n",
    "        \n",
    "        self.max_torque = 2.0\n",
    "    \n",
    "    def ode_forward(self, t, z):\n",
    "        \"\"\"ODE function: dz/dt = f(z, t)\"\"\"\n",
    "        batch_size = z.shape[0]\n",
    "        t_vec = t * torch.ones(batch_size, 1)\n",
    "        inp = torch.cat([z, t_vec], dim=1)\n",
    "        return self.ode_func(inp)\n",
    "    \n",
    "    def get_control(self, state):\n",
    "        \"\"\"Compute control action from state\"\"\"\n",
    "        z = self.encoder(state)\n",
    "        u = self.policy(z) * self.max_torque\n",
    "        return u\n",
    "    \n",
    "    def forward(self, state0, t_span, dt=0.05):\n",
    "        \"\"\"\n",
    "        Roll out trajectory with neural controller\n",
    "        \n",
    "        Process:\n",
    "        1. Encode initial state: z₀ = encoder(x₀)\n",
    "        2. For each time step:\n",
    "           a. Compute control: u = policy(z)\n",
    "           b. Apply control to real dynamics\n",
    "           c. Evolve latent state with ODE\n",
    "        \"\"\"\n",
    "        # Initialize\n",
    "        z = self.encoder(state0)\n",
    "        state = state0.clone()\n",
    "        \n",
    "        t = t_span[0]\n",
    "        trajectory = [state0.clone()]\n",
    "        controls = []\n",
    "        \n",
    "        # Dynamics model\n",
    "        dynamics = PendulumDynamics()\n",
    "        \n",
    "        while t < t_span[1]:\n",
    "            # Get control action\n",
    "            u = self.policy(z) * self.max_torque\n",
    "            controls.append(u.clone())\n",
    "            \n",
    "            # Update real state using true dynamics\n",
    "            dx = dynamics.dynamics(state, u)\n",
    "            state = state + dx * dt\n",
    "            \n",
    "            # Update latent state using Neural ODE (Euler step)\n",
    "            dz = self.ode_forward(t, z)\n",
    "            z = z + dz * dt\n",
    "            \n",
    "            t += dt\n",
    "            trajectory.append(state.clone())\n",
    "        \n",
    "        return torch.stack(trajectory), torch.stack(controls)\n",
    "\n",
    "\n",
    "def train_pendulum_controller():\n",
    "    \"\"\"\n",
    "    Train Neural ODE controller for inverted pendulum\n",
    "    \n",
    "    Goal: Balance pendulum at upright position (θ = 0)\n",
    "    \"\"\"\n",
    "    print(\"=\" * 80)\n",
    "    print(\"ROBOT CONTROL: Neural ODE Controller for Inverted Pendulum\")\n",
    "    print(\"=\" * 80)\n",
    "    print()\n",
    "    print(\"Mathematical Setup:\")\n",
    "    print(\"-\" * 80)\n",
    "    print(\"Dynamics: θ̈ = (g/L)sin(θ) - (b/mL²)θ̇ + (1/mL²)τ\")\n",
    "    print(\"State: x = [θ, θ̇]ᵀ\")\n",
    "    print(\"Control: τ ∈ [-2, 2] N·m\")\n",
    "    print(\"Objective: Minimize ‖θ - θ_ref‖² + λ‖τ‖²\")\n",
    "    print(\"-\" * 80)\n",
    "    print()\n",
    "    \n",
    "    # Create model\n",
    "    controller = NeuralControllerODE(state_dim=2, latent_dim=8, hidden_dim=64)\n",
    "    optimizer = optim.Adam(controller.parameters(), lr=0.001)\n",
    "    \n",
    "    # Training parameters\n",
    "    n_episodes = 500\n",
    "    batch_size = 32\n",
    "    t_horizon = 5.0\n",
    "    dt = 0.05\n",
    "    \n",
    "    losses = []\n",
    "    \n",
    "    for episode in range(n_episodes):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Sample initial conditions (pendulum starts at various angles)\n",
    "        theta0 = torch.rand(batch_size, 1) * 2 * np.pi - np.pi  # [-π, π]\n",
    "        theta_dot0 = torch.rand(batch_size, 1) * 2 - 1  # [-1, 1]\n",
    "        state0 = torch.cat([theta0, theta_dot0], dim=1)\n",
    "        \n",
    "        # Roll out trajectory\n",
    "        trajectory, controls = controller(state0, [0.0, t_horizon], dt=dt)\n",
    "        \n",
    "        # Reference: upright position\n",
    "        theta_ref = torch.zeros_like(trajectory[..., 0:1])\n",
    "        \n",
    "        # Compute loss\n",
    "        # 1. Tracking error\n",
    "        tracking_loss = torch.mean((trajectory[..., 0:1] - theta_ref) ** 2)\n",
    "        \n",
    "        # 2. Control cost\n",
    "        control_loss = 0.1 * torch.mean(controls ** 2)\n",
    "        \n",
    "        # 3. Velocity penalty (smooth motion)\n",
    "        velocity_loss = 0.01 * torch.mean(trajectory[..., 1:2] ** 2)\n",
    "        \n",
    "        # Total loss\n",
    "        loss = tracking_loss + control_loss + velocity_loss\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(controller.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        \n",
    "        losses.append(loss.item())\n",
    "        \n",
    "        if (episode + 1) % 100 == 0:\n",
    "            print(f\"Episode {episode+1}/{n_episodes}\")\n",
    "            print(f\"  Total Loss: {loss.item():.6f}\")\n",
    "            print(f\"  Tracking: {tracking_loss.item():.6f}\")\n",
    "            print(f\"  Control: {control_loss.item():.6f}\")\n",
    "            print(f\"  Velocity: {velocity_loss.item():.6f}\")\n",
    "            print()\n",
    "    \n",
    "    # Test controller\n",
    "    print(\"Testing controller on new initial conditions...\")\n",
    "    controller.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Test from challenging initial condition\n",
    "        state0_test = torch.tensor([[np.pi * 0.8, 0.0]])  # Start at ~144 degrees\n",
    "        trajectory_test, controls_test = controller(state0_test, [0.0, 10.0], dt=0.02)\n",
    "        \n",
    "        traj_np = trajectory_test.squeeze().numpy()\n",
    "        ctrl_np = controls_test.squeeze().numpy()\n",
    "        times = np.arange(len(traj_np)) * 0.02\n",
    "    \n",
    "    # Visualization\n",
    "    fig = plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    # Plot 1: Training loss\n",
    "    ax1 = plt.subplot(3, 2, 1)\n",
    "    ax1.plot(losses, linewidth=2)\n",
    "    ax1.set_xlabel('Episode', fontsize=12)\n",
    "    ax1.set_ylabel('Total Loss', fontsize=12)\n",
    "    ax1.set_title('Training Progress', fontsize=14, fontweight='bold')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    ax1.set_yscale('log')\n",
    "    \n",
    "    # Plot 2: Angle trajectory\n",
    "    ax2 = plt.subplot(3, 2, 2)\n",
    "    ax2.plot(times, np.rad2deg(traj_np[:, 0]), linewidth=2, label='θ (angle)')\n",
    "    ax2.axhline(y=0, color='r', linestyle='--', label='Target (0°)', linewidth=2)\n",
    "    ax2.set_xlabel('Time (s)', fontsize=12)\n",
    "    ax2.set_ylabel('Angle (degrees)', fontsize=12)\n",
    "    ax2.set_title('Pendulum Angle vs Time', fontsize=14, fontweight='bold')\n",
    "    ax2.legend(fontsize=10)\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 3: Angular velocity\n",
    "    ax3 = plt.subplot(3, 2, 3)\n",
    "    ax3.plot(times, traj_np[:, 1], linewidth=2, color='orange')\n",
    "    ax3.set_xlabel('Time (s)', fontsize=12)\n",
    "    ax3.set_ylabel('Angular Velocity (rad/s)', fontsize=12)\n",
    "    ax3.set_title('Angular Velocity vs Time', fontsize=14, fontweight='bold')\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 4: Control input\n",
    "    ax4 = plt.subplot(3, 2, 4)\n",
    "    ctrl_times = np.arange(len(ctrl_np)) * 0.02\n",
    "    ax4.plot(ctrl_times, ctrl_np, linewidth=2, color='green')\n",
    "    ax4.set_xlabel('Time (s)', fontsize=12)\n",
    "    ax4.set_ylabel('Torque (N·m)', fontsize=12)\n",
    "    ax4.set_title('Control Input vs Time', fontsize=14, fontweight='bold')\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "    ax4.axhline(y=2.0, color='r', linestyle='--', alpha=0.5, label='Max torque')\n",
    "    ax4.axhline(y=-2.0, color='r', linestyle='--', alpha=0.5)\n",
    "    ax4.legend(fontsize=10)\n",
    "    \n",
    "    # Plot 5: Phase portrait\n",
    "    ax5 = plt.subplot(3, 2, 5)\n",
    "    ax5.plot(np.rad2deg(traj_np[:, 0]), traj_np[:, 1], linewidth=2)\n",
    "    ax5.scatter(np.rad2deg(traj_np[0, 0]), traj_np[0, 1], \n",
    "                c='green', s=100, marker='o', label='Start', zorder=5)\n",
    "    ax5.scatter(0, 0, c='red', s=100, marker='*', label='Target', zorder=5)\n",
    "    ax5.set_xlabel('Angle (degrees)', fontsize=12)\n",
    "    ax5.set_ylabel('Angular Velocity (rad/s)', fontsize=12)\n",
    "    ax5.set_title('Phase Portrait', fontsize=14, fontweight='bold')\n",
    "    ax5.legend(fontsize=10)\n",
    "    ax5.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 6: Energy analysis\n",
    "    ax6 = plt.subplot(3, 2, 6)\n",
    "    m, L, g = 1.0, 1.0, 9.81\n",
    "    potential_energy = m * g * L * (1 - np.cos(traj_np[:, 0]))  # PE = mgL(1-cosθ)\n",
    "    kinetic_energy = 0.5 * m * L**2 * traj_np[:, 1]**2  # KE = ½mL²θ̇²\n",
    "    total_energy = potential_energy + kinetic_energy\n",
    "    \n",
    "    ax6.plot(times, potential_energy, linewidth=2, label='Potential Energy', alpha=0.7)\n",
    "    ax6.plot(times, kinetic_energy, linewidth=2, label='Kinetic Energy', alpha=0.7)\n",
    "    ax6.plot(times, total_energy, linewidth=2, label='Total Energy', linestyle='--')\n",
    "    ax6.set_xlabel('Time (s)', fontsize=12)\n",
    "    ax6.set_ylabel('Energy (J)', fontsize=12)\n",
    "    ax6.set_title('Energy Analysis', fontsize=14, fontweight='bold')\n",
    "    ax6.legend(fontsize=10)\n",
    "    ax6.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('pendulum_control_results.png', dpi=150, bbox_inches='tight')\n",
    "    print(\"\\nResults saved to 'pendulum_control_results.png'\")\n",
    "    plt.close()\n",
    "    \n",
    "    return controller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d810f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# PART 4: STOCHASTIC ROBOT CONTROL with Uncertainty\n",
    "# ============================================================================\n",
    "\n",
    "def train_stochastic_pendulum():\n",
    "    \"\"\"\n",
    "    Train Neural SDE for robust pendulum control under uncertainty\n",
    "    \n",
    "    Mathematical Framework:\n",
    "    ----------------------\n",
    "    State dynamics with noise:\n",
    "    dx = f(x, u, t)dt + g(x, t)dW\n",
    "    \n",
    "    where g(x, t) models:\n",
    "    - Model uncertainty\n",
    "    - External disturbances\n",
    "    - Sensor noise\n",
    "    \n",
    "    Training:\n",
    "    --------\n",
    "    Learn both drift and diffusion simultaneously\n",
    "    Loss = E[‖x - x_ref‖²] + λE[‖u‖²] + β·KL[q(noise)||p(noise)]\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"STOCHASTIC ROBOT CONTROL: Neural SDE for Robust Pendulum Control\")\n",
    "    print(\"=\" * 80)\n",
    "    print()\n",
    "    print(\"Mathematical Setup:\")\n",
    "    print(\"-\" * 80)\n",
    "    print(\"Stochastic Dynamics: dx = f(x,u)dt + g(x)dW\")\n",
    "    print(\"where:\")\n",
    "    print(\"  f(x,u) = drift (controlled dynamics)\")\n",
    "    print(\"  g(x) = diffusion (uncertainty/noise)\")\n",
    "    print(\"  dW = Wiener process (Brownian motion)\")\n",
    "    print()\n",
    "    print(\"Discretization (Euler-Maruyama):\")\n",
    "    print(\"  x(t+Δt) = x(t) + f(x,u)Δt + g(x)√Δt·ε, ε ~ N(0,I)\")\n",
    "    print(\"-\" * 80)\n",
    "    print()\n",
    "    \n",
    "    # Create stochastic model\n",
    "    sde_model = NeuralSDE(state_dim=2, hidden_dim=32, noise_type='diagonal')\n",
    "    \n",
    "    # Policy network (separate from SDE)\n",
    "    policy = nn.Sequential(\n",
    "        nn.Linear(2, 32),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(32, 1),\n",
    "        nn.Tanh()\n",
    "    )\n",
    "    \n",
    "    optimizer = optim.Adam(list(sde_model.parameters()) + list(policy.parameters()), \n",
    "                          lr=0.002)\n",
    "    \n",
    "    # Training parameters\n",
    "    n_episodes = 300\n",
    "    batch_size = 16\n",
    "    t_horizon = 5.0\n",
    "    dt = 0.05\n",
    "    max_torque = 2.0\n",
    "    \n",
    "    losses = []\n",
    "    noise_scales = []\n",
    "    \n",
    "    dynamics = PendulumDynamics()\n",
    "    \n",
    "    for episode in range(n_episodes):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Sample initial conditions\n",
    "        theta0 = torch.rand(batch_size, 1) * np.pi - np.pi/2  # [-π/2, π/2]\n",
    "        theta_dot0 = torch.rand(batch_size, 1) * 0.5 - 0.25\n",
    "        state = torch.cat([theta0, theta_dot0], dim=1)\n",
    "        \n",
    "        # Roll out trajectory with stochastic dynamics\n",
    "        trajectory = [state.clone()]\n",
    "        controls = []\n",
    "        \n",
    "        t = 0.0\n",
    "        while t < t_horizon:\n",
    "            # Compute control\n",
    "            u = policy(state) * max_torque\n",
    "            controls.append(u)\n",
    "            \n",
    "            # Deterministic dynamics\n",
    "            f_det = dynamics.dynamics(state, u)\n",
    "            \n",
    "            # Stochastic component from Neural SDE\n",
    "            g_stoch = sde_model.diffusion(state, t)\n",
    "            dW = torch.randn_like(state) * np.sqrt(dt)\n",
    "            \n",
    "            # Combined update (Euler-Maruyama)\n",
    "            state = state + f_det * dt + g_stoch * dW\n",
    "            \n",
    "            trajectory.append(state.clone())\n",
    "            t += dt\n",
    "        \n",
    "        trajectory = torch.stack(trajectory)\n",
    "        controls = torch.stack(controls)\n",
    "        \n",
    "        # Losses\n",
    "        theta_ref = torch.zeros_like(trajectory[..., 0:1])\n",
    "        tracking_loss = torch.mean((trajectory[..., 0:1] - theta_ref) ** 2)\n",
    "        control_loss = 0.05 * torch.mean(controls ** 2)\n",
    "        \n",
    "        # Penalize excessive noise (we want minimal necessary uncertainty)\n",
    "        noise_penalty = 0.01 * torch.mean(g_stoch ** 2)\n",
    "        \n",
    "        loss = tracking_loss + control_loss + noise_penalty\n",
    "        \n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(list(sde_model.parameters()) + \n",
    "                                      list(policy.parameters()), 1.0)\n",
    "        optimizer.step()\n",
    "        \n",
    "        losses.append(loss.item())\n",
    "        noise_scales.append(torch.mean(g_stoch).item())\n",
    "        \n",
    "        if (episode + 1) % 60 == 0:\n",
    "            print(f\"Episode {episode+1}/{n_episodes}\")\n",
    "            print(f\"  Loss: {loss.item():.6f}\")\n",
    "            print(f\"  Tracking: {tracking_loss.item():.6f}\")\n",
    "            print(f\"  Avg Noise Scale: {noise_scales[-1]:.6f}\")\n",
    "            print()\n",
    "    \n",
    "    # Test with multiple rollouts to show uncertainty\n",
    "    print(\"Testing stochastic controller with 20 rollouts...\")\n",
    "    sde_model.eval()\n",
    "    policy.eval()\n",
    "    \n",
    "    n_rollouts = 20\n",
    "    all_trajectories = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        state0_test = torch.tensor([[np.pi * 0.5, 0.0]])  # Start at 90 degrees\n",
    "        \n",
    "        for _ in range(n_rollouts):\n",
    "            state = state0_test.clone()\n",
    "            traj = [state.clone()]\n",
    "            \n",
    "            t = 0.0\n",
    "            while t < 8.0:\n",
    "                u = policy(state) * max_torque\n",
    "                f_det = dynamics.dynamics(state, u)\n",
    "                g_stoch = sde_model.diffusion(state, t)\n",
    "                dW = torch.randn_like(state) * np.sqrt(0.05)\n",
    "                \n",
    "                state = state + f_det * 0.05 + g_stoch * dW\n",
    "                traj.append(state.clone())\n",
    "                t += 0.05\n",
    "            \n",
    "            all_trajectories.append(torch.stack(traj).squeeze().numpy())\n",
    "    \n",
    "    # Visualization\n",
    "    fig = plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    # Plot 1: Training loss\n",
    "    ax1 = plt.subplot(2, 3, 1)\n",
    "    ax1.plot(losses, linewidth=2, color='blue')\n",
    "    ax1.set_xlabel('Episode', fontsize=12)\n",
    "    ax1.set_ylabel('Total Loss', fontsize=12)\n",
    "    ax1.set_title('Training Progress (SDE)', fontsize=14, fontweight='bold')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 2: Learned noise scale\n",
    "    ax2 = plt.subplot(2, 3, 2)\n",
    "    ax2.plot(noise_scales, linewidth=2, color='red')\n",
    "    ax2.set_xlabel('Episode', fontsize=12)\n",
    "    ax2.set_ylabel('Avg Diffusion Scale', fontsize=12)\n",
    "    ax2.set_title('Learned Noise Intensity', fontsize=14, fontweight='bold')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 3: Multiple stochastic rollouts (angle)\n",
    "    ax3 = plt.subplot(2, 3, 3)\n",
    "    times = np.arange(all_trajectories[0].shape[0]) * 0.05\n",
    "    for traj in all_trajectories:\n",
    "        ax3.plot(times, np.rad2deg(traj[:, 0]), alpha=0.4, linewidth=1)\n",
    "    \n",
    "    # Mean trajectory\n",
    "    mean_traj = np.mean([traj[:, 0] for traj in all_trajectories], axis=0)\n",
    "    std_traj = np.std([traj[:, 0] for traj in all_trajectories], axis=0)\n",
    "    ax3.plot(times, np.rad2deg(mean_traj), 'b-', linewidth=3, label='Mean')\n",
    "    ax3.fill_between(times, \n",
    "                     np.rad2deg(mean_traj - std_traj), \n",
    "                     np.rad2deg(mean_traj + std_traj),\n",
    "                     alpha=0.3, label='±1 std')\n",
    "    ax3.axhline(y=0, color='r', linestyle='--', linewidth=2, label='Target')\n",
    "    ax3.set_xlabel('Time (s)', fontsize=12)\n",
    "    ax3.set_ylabel('Angle (degrees)', fontsize=12)\n",
    "    ax3.set_title('Stochastic Trajectories (20 rollouts)', fontsize=14, fontweight='bold')\n",
    "    ax3.legend(fontsize=9)\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 4: Phase portrait with uncertainty\n",
    "    ax4 = plt.subplot(2, 3, 4)\n",
    "    for traj in all_trajectories:\n",
    "        ax4.plot(np.rad2deg(traj[:, 0]), traj[:, 1], alpha=0.3, linewidth=1)\n",
    "    ax4.scatter(0, 0, c='red', s=200, marker='*', label='Target', zorder=5)\n",
    "    ax4.scatter(np.rad2deg(all_trajectories[0][0, 0]), \n",
    "               all_trajectories[0][0, 1],\n",
    "               c='green', s=100, marker='o', label='Start', zorder=5)\n",
    "    ax4.set_xlabel('Angle (degrees)', fontsize=12)\n",
    "    ax4.set_ylabel('Angular Velocity (rad/s)', fontsize=12)\n",
    "    ax4.set_title('Phase Portrait (with Noise)', fontsize=14, fontweight='bold')\n",
    "    ax4.legend(fontsize=10)\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 5: Uncertainty quantification\n",
    "    ax5 = plt.subplot(2, 3, 5)\n",
    "    angle_std = np.std([traj[:, 0] for traj in all_trajectories], axis=0)\n",
    "    ax5.plot(times, np.rad2deg(angle_std), linewidth=2, color='purple')\n",
    "    ax5.set_xlabel('Time (s)', fontsize=12)\n",
    "    ax5.set_ylabel('Std Dev (degrees)', fontsize=12)\n",
    "    ax5.set_title('Uncertainty Evolution', fontsize=14, fontweight='bold')\n",
    "    ax5.grid(True, alpha=0.3)\n",
    "    ax5.fill_between(times, 0, np.rad2deg(angle_std), alpha=0.3)\n",
    "    \n",
    "    # Plot 6: Comparison with/without noise at key timesteps\n",
    "    ax6 = plt.subplot(2, 3, 6)\n",
    "    timesteps = [0, 50, 100, 150]  # indices\n",
    "    angles_at_times = [[traj[t, 0] for traj in all_trajectories] for t in timesteps]\n",
    "    \n",
    "    positions = np.arange(len(timesteps))\n",
    "    bp = ax6.boxplot(angles_at_times, positions=positions, widths=0.6,\n",
    "                     patch_artist=True, showfliers=False)\n",
    "    for patch in bp['boxes']:\n",
    "        patch.set_facecolor('lightblue')\n",
    "    \n",
    "    ax6.set_xticks(positions)\n",
    "    ax6.set_xticklabels([f't={times[t]:.1f}s' for t in timesteps])\n",
    "    ax6.set_ylabel('Angle (rad)', fontsize=12)\n",
    "    ax6.set_title('Uncertainty Distribution Over Time', fontsize=14, fontweight='bold')\n",
    "    ax6.axhline(y=0, color='r', linestyle='--', linewidth=2, alpha=0.7)\n",
    "    ax6.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('stochastic_pendulum_results.png', dpi=150, bbox_inches='tight')\n",
    "    print(\"Results saved to 'stochastic_pendulum_results.png'\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5a48ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# PART 5: MODEL PREDICTIVE CONTROL with Neural ODE\n",
    "# ============================================================================\n",
    "\n",
    "class NeuralMPC:\n",
    "    \"\"\"\n",
    "    Model Predictive Control using Neural ODE\n",
    "    \n",
    "    Mathematical Formulation:\n",
    "    ------------------------\n",
    "    At each time step t, solve:\n",
    "    \n",
    "    min  Σᵢ [‖z(tᵢ) - z_ref(tᵢ)‖²_Q + ‖u(tᵢ)‖²_R]\n",
    "    u\n",
    "    \n",
    "    subject to:\n",
    "        dz/dt = f_neural(z, u, t)  (Neural ODE dynamics)\n",
    "        u_min ≤ u ≤ u_max           (Control constraints)\n",
    "        z(t₀) = z_current           (Initial condition)\n",
    "    \n",
    "    Where:\n",
    "    - z: state trajectory\n",
    "    - u: control sequence\n",
    "    - Q: state cost matrix\n",
    "    - R: control cost matrix\n",
    "    - Horizon: T = N·Δt\n",
    "    \n",
    "    Implementation:\n",
    "    --------------\n",
    "    1. Learn dynamics model: Neural ODE\n",
    "    2. At each timestep:\n",
    "       a. Use current state as initial condition\n",
    "       b. Optimize control sequence u[0:N] via gradient descent\n",
    "       c. Apply first control u[0]\n",
    "       d. Repeat (receding horizon)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, state_dim=2, control_dim=1, horizon=10, dt=0.1):\n",
    "        self.state_dim = state_dim\n",
    "        self.control_dim = control_dim\n",
    "        self.horizon = horizon\n",
    "        self.dt = dt\n",
    "        \n",
    "        # Neural ODE dynamics model\n",
    "        self.dynamics_model = nn.Sequential(\n",
    "            nn.Linear(state_dim + control_dim + 1, 64),  # +1 for time\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(64, state_dim)\n",
    "        )\n",
    "        \n",
    "        # Cost matrices\n",
    "        self.Q = torch.eye(state_dim, dtype=torch.float32) * 10.0  # state cost\n",
    "        self.R = torch.eye(control_dim, dtype=torch.float32) * 0.1  # control cost\n",
    "        \n",
    "        self.max_control = 2.0\n",
    "\n",
    "    def dynamics(self, state, control, t):\n",
    "        \"\"\"Learned dynamics: dx/dt = f(x, u, t)\"\"\"\n",
    "        batch_size = state.shape[0]\n",
    "        t_tensor = torch.tensor([[t]], dtype=torch.float32).expand(batch_size, 1)  # Fix: expand to match batch size\n",
    "        inp = torch.cat([state, control, t_tensor], dim=1)\n",
    "        return self.dynamics_model(inp)\n",
    "    \n",
    "    def rollout(self, state0, control_sequence, t0):\n",
    "        \"\"\"\n",
    "        Roll out trajectory given control sequence\n",
    "        \n",
    "        Args:\n",
    "            state0: [1, state_dim] initial state\n",
    "            control_sequence: [horizon, 1, control_dim] controls\n",
    "            t0: initial time\n",
    "        \n",
    "        Returns:\n",
    "            trajectory: [horizon+1, 1, state_dim]\n",
    "        \"\"\"\n",
    "        state = state0\n",
    "        trajectory = [state0]\n",
    "        \n",
    "        for i, u in enumerate(control_sequence):\n",
    "            t = t0 + i * self.dt\n",
    "            dx = self.dynamics(state, u, t)\n",
    "            state = state + dx * self.dt\n",
    "            trajectory.append(state)\n",
    "        \n",
    "        return torch.stack(trajectory)\n",
    "\n",
    "    def compute_cost(self, trajectory, controls, reference):\n",
    "        \"\"\"\n",
    "        Compute MPC cost function\n",
    "    \n",
    "        J = Σ (z - z_ref)ᵀQ(z - z_ref) + uᵀRu\n",
    "        Args:\n",
    "            trajectory: [horizon+1, 1, state_dim]\n",
    "            controls: [horizon, 1, control_dim]\n",
    "            reference: [horizon+1, 1, state_dim]\n",
    "        \"\"\"\n",
    "        # Ensure consistent dtype\n",
    "        trajectory = trajectory.float()\n",
    "        reference = reference.float()\n",
    "        controls = controls.float()\n",
    "    \n",
    "        # State cost\n",
    "        state_error = trajectory - reference\n",
    "        state_cost = 0.0\n",
    "        for i in range(len(trajectory)):\n",
    "            error = state_error[i].view(-1)  # Flatten to 1D vector\n",
    "            # Quadratic form: error^T @ Q @ error\n",
    "            state_cost += (error @ self.Q @ error)\n",
    "    \n",
    "        # Control cost\n",
    "        control_cost = 0.0\n",
    "        for u in controls:\n",
    "            u_vec = u.view(-1)  # Flatten to 1D vector\n",
    "            # Quadratic form: u^T @ R @ u\n",
    "            control_cost += (u_vec @ self.R @ u_vec)\n",
    "    \n",
    "        return state_cost + control_cost\n",
    "    \n",
    "    def optimize_controls(self, state0, reference, t0, n_iterations=20):\n",
    "        \"\"\"\n",
    "        Optimize control sequence for MPC\n",
    "        \n",
    "        Uses gradient descent to minimize cost function\n",
    "        \"\"\"\n",
    "        # Initialize control sequence (learnable parameters)\n",
    "        controls = torch.zeros(self.horizon, 1, self.control_dim, requires_grad=True)\n",
    "        \n",
    "        optimizer = optim.Adam([controls], lr=0.1)\n",
    "        \n",
    "        for iteration in range(n_iterations):\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Apply control constraints via tanh\n",
    "            controls_bounded = torch.tanh(controls) * self.max_control\n",
    "            \n",
    "            # Roll out trajectory\n",
    "            trajectory = self.rollout(state0, controls_bounded, t0)\n",
    "            \n",
    "            # Compute cost\n",
    "            cost = self.compute_cost(trajectory, controls_bounded, reference)\n",
    "            \n",
    "            # Optimize\n",
    "            cost.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        # Return optimized controls\n",
    "        with torch.no_grad():\n",
    "            optimal_controls = torch.tanh(controls) * self.max_control\n",
    "        \n",
    "        return optimal_controls\n",
    "\n",
    "\n",
    "def train_and_test_mpc():\n",
    "    \"\"\"\n",
    "    Train Neural MPC for pendulum control\n",
    "    \n",
    "    Process:\n",
    "    1. Learn dynamics model from data\n",
    "    2. Use learned model for MPC optimization\n",
    "    3. Test on tracking task\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"MODEL PREDICTIVE CONTROL: Neural ODE-based MPC\")\n",
    "    print(\"=\" * 80)\n",
    "    print()\n",
    "    print(\"Mathematical Framework:\")\n",
    "    print(\"-\" * 80)\n",
    "    print(\"Optimization Problem (solved at each timestep):\")\n",
    "    print()\n",
    "    print(\"  min  Σᵢ₌₀ᴺ [‖xᵢ - x_ref,ᵢ‖²_Q + ‖uᵢ‖²_R]\")\n",
    "    print(\"  u\")\n",
    "    print()\n",
    "    print(\"  subject to:\")\n",
    "    print(\"    dx/dt = f_neural(x, u, t)\")\n",
    "    print(\"    u_min ≤ u ≤ u_max\")\n",
    "    print(\"    x₀ = x_current\")\n",
    "    print()\n",
    "    print(\"Receding Horizon: Apply u₀, observe new state, re-optimize\")\n",
    "    print(\"-\" * 80)\n",
    "    print()\n",
    "    \n",
    "    # Step 1: Generate training data for dynamics model\n",
    "    print(\"Step 1: Collecting data for dynamics model...\")\n",
    "    dynamics = PendulumDynamics()\n",
    "    \n",
    "    n_samples = 1000\n",
    "    states = []\n",
    "    controls = []\n",
    "    next_states = []\n",
    "    \n",
    "    for _ in range(n_samples):\n",
    "        # Random state\n",
    "        theta = np.random.uniform(-np.pi, np.pi)\n",
    "        theta_dot = np.random.uniform(-2, 2)\n",
    "        state = torch.tensor([[theta, theta_dot]], dtype=torch.float32)\n",
    "        \n",
    "        # Random control\n",
    "        u = torch.tensor([[np.random.uniform(-2, 2)]], dtype=torch.float32)\n",
    "        \n",
    "        # Next state\n",
    "        dx = dynamics.dynamics(state, u)\n",
    "        next_state = state + dx * 0.1\n",
    "        \n",
    "        states.append(state)\n",
    "        controls.append(u)\n",
    "        next_states.append(next_state)\n",
    "    \n",
    "    states = torch.cat(states)\n",
    "    controls = torch.cat(controls)\n",
    "    next_states = torch.cat(next_states)\n",
    "    \n",
    "    # Step 2: Train dynamics model\n",
    "    print(\"Step 2: Training dynamics model...\")\n",
    "    mpc = NeuralMPC(state_dim=2, control_dim=1, horizon=15, dt=0.1)\n",
    "    optimizer = optim.Adam(mpc.dynamics_model.parameters(), lr=0.001)\n",
    "    \n",
    "    for epoch in range(500):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Predict next states\n",
    "        pred_dx = mpc.dynamics(states, controls, 0.0)\n",
    "        pred_next_states = states + pred_dx * 0.1\n",
    "        \n",
    "        # Loss\n",
    "        loss = torch.mean((pred_next_states - next_states) ** 2)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (epoch + 1) % 100 == 0:\n",
    "            print(f\"  Epoch {epoch+1}/500, Dynamics Loss: {loss.item():.6f}\")\n",
    "    \n",
    "    print(\"\\nStep 3: Running MPC controller...\")\n",
    "    \n",
    "    # Step 3: Test MPC\n",
    "    # Track a reference trajectory\n",
    "    t_sim = 10.0\n",
    "    dt = 0.1\n",
    "    n_steps = int(t_sim / dt)\n",
    "    \n",
    "    # Initial state\n",
    "    state = torch.tensor([[np.pi * 0.7, 0.0]], dtype=torch.float32)\n",
    "    \n",
    "    # Reference trajectory (sinusoidal)\n",
    "    times = np.linspace(0, t_sim, n_steps)\n",
    "    ref_angles = 0.3 * np.sin(2 * np.pi * 0.2 * times)  # slow oscillation\n",
    "    \n",
    "    trajectory = [state.clone()]\n",
    "    controls_applied = []\n",
    "    computation_times = []\n",
    "    \n",
    "    import time as time_module\n",
    "    \n",
    "    for i in range(n_steps - 1):\n",
    "        t = i * dt\n",
    "\n",
    "        # Create reference for horizon\n",
    "        ref_traj = []\n",
    "        for j in range(mpc.horizon + 1):\n",
    "            idx = min(i + j, n_steps - 1)\n",
    "            ref_state = torch.tensor([[ref_angles[idx], 0.0]], dtype=torch.float32)  # Added dtype\n",
    "            ref_traj.append(ref_state)\n",
    "        ref_traj = torch.stack(ref_traj)\n",
    "        \n",
    "        # Optimize controls\n",
    "        start_time = time_module.time()\n",
    "        optimal_controls = mpc.optimize_controls(state, ref_traj, t, n_iterations=15)\n",
    "        comp_time = time_module.time() - start_time\n",
    "        computation_times.append(comp_time)\n",
    "        \n",
    "        # Apply first control\n",
    "        u = optimal_controls[0]\n",
    "        controls_applied.append(u.clone())\n",
    "        \n",
    "        # Update state using TRUE dynamics\n",
    "        dx = dynamics.dynamics(state, u)\n",
    "        state = state + dx * dt\n",
    "        trajectory.append(state.clone())\n",
    "    \n",
    "\n",
    "    trajectory = torch.stack(trajectory).squeeze().detach().numpy()\n",
    "    controls_applied = torch.stack(controls_applied).squeeze().detach().numpy()\n",
    "    \n",
    "    # Trim trajectory to match\n",
    "    trajectory = trajectory[:-1]  # Remove last point to match controls length\n",
    "\n",
    "    print(f\"Average computation time per step: {np.mean(computation_times)*1000:.2f} ms\")\n",
    "    \n",
    "    # Visualization\n",
    "    fig = plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    # Plot 1: Tracking performance\n",
    "    ax1 = plt.subplot(2, 3, 1)\n",
    "    ax1.plot(times[:-1], np.rad2deg(trajectory[:, 0]), linewidth=2, label='Actual')\n",
    "    ax1.plot(times, np.rad2deg(ref_angles), 'r--', linewidth=2, label='Reference')\n",
    "    ax1.set_xlabel('Time (s)', fontsize=12)\n",
    "    ax1.set_ylabel('Angle (degrees)', fontsize=12)\n",
    "    ax1.set_title('MPC Tracking Performance', fontsize=14, fontweight='bold')\n",
    "    ax1.legend(fontsize=11)\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 2: Tracking error\n",
    "    ax2 = plt.subplot(2, 3, 2)\n",
    "    tracking_error = np.rad2deg(trajectory[:, 0]) - np.rad2deg(ref_angles[:-1])\n",
    "    ax2.plot(times[:-1], tracking_error, linewidth=2, color='red')\n",
    "    ax2.axhline(y=0, color='k', linestyle='--', alpha=0.5)\n",
    "    ax2.set_xlabel('Time (s)', fontsize=12)\n",
    "    ax2.set_ylabel('Error (degrees)', fontsize=12)\n",
    "    ax2.set_title('Tracking Error', fontsize=14, fontweight='bold')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    rms_error = np.sqrt(np.mean(tracking_error**2))\n",
    "    ax2.text(0.02, 0.98, f'RMS Error: {rms_error:.2f}°', \n",
    "            transform=ax2.transAxes, fontsize=11,\n",
    "            verticalalignment='top', bbox=dict(boxstyle='round', facecolor='wheat'))\n",
    "    \n",
    "    # Plot 3: Control input\n",
    "    ax3 = plt.subplot(2, 3, 3)\n",
    "    ax3.plot(times[:-1], controls_applied, linewidth=2, color='green')\n",
    "    ax3.axhline(y=2.0, color='r', linestyle='--', alpha=0.5, label='Limits')\n",
    "    ax3.axhline(y=-2.0, color='r', linestyle='--', alpha=0.5)\n",
    "    ax3.set_xlabel('Time (s)', fontsize=12)\n",
    "    ax3.set_ylabel('Torque (N·m)', fontsize=12)\n",
    "    ax3.set_title('MPC Control Input', fontsize=14, fontweight='bold')\n",
    "    ax3.legend(fontsize=10)\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 4: Phase portrait\n",
    "    ax4 = plt.subplot(2, 3, 4)\n",
    "    ax4.plot(np.rad2deg(trajectory[:, 0]), trajectory[:, 1], linewidth=2)\n",
    "    ax4.scatter(np.rad2deg(trajectory[0, 0]), trajectory[0, 1], \n",
    "               c='green', s=100, marker='o', label='Start', zorder=5)\n",
    "    ax4.plot(np.rad2deg(ref_angles), np.zeros_like(ref_angles), \n",
    "            'r--', linewidth=2, alpha=0.7, label='Reference path')\n",
    "    ax4.set_xlabel('Angle (degrees)', fontsize=12)\n",
    "    ax4.set_ylabel('Angular Velocity (rad/s)', fontsize=12)\n",
    "    ax4.set_title('Phase Portrait', fontsize=14, fontweight='bold')\n",
    "    ax4.legend(fontsize=10)\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 5: Computation time\n",
    "    ax5 = plt.subplot(2, 3, 5)\n",
    "    ax5.plot(times[:-1], np.array(computation_times) * 1000, linewidth=2, color='purple')\n",
    "    ax5.set_xlabel('Time (s)', fontsize=12)\n",
    "    ax5.set_ylabel('Computation Time (ms)', fontsize=12)\n",
    "    ax5.set_title('MPC Computation Time', fontsize=14, fontweight='bold')\n",
    "    ax5.grid(True, alpha=0.3)\n",
    "    ax5.axhline(y=np.mean(computation_times)*1000, color='r', \n",
    "               linestyle='--', label=f'Mean: {np.mean(computation_times)*1000:.1f} ms')\n",
    "    ax5.legend(fontsize=10)\n",
    "    \n",
    "    # Plot 6: Control effort\n",
    "    ax6 = plt.subplot(2, 3, 6)\n",
    "    cumulative_effort = np.cumsum(np.abs(controls_applied))\n",
    "    ax6.plot(times[:-1], cumulative_effort, linewidth=2, color='brown')\n",
    "    ax6.set_xlabel('Time (s)', fontsize=12)\n",
    "    ax6.set_ylabel('Cumulative |Torque| (N·m·s)', fontsize=12)\n",
    "    ax6.set_title('Control Effort', fontsize=14, fontweight='bold')\n",
    "    ax6.grid(True, alpha=0.3)\n",
    "    total_effort = cumulative_effort[-1]\n",
    "    ax6.text(0.02, 0.98, f'Total: {total_effort:.2f} N·m·s', \n",
    "            transform=ax6.transAxes, fontsize=11,\n",
    "            verticalalignment='top', bbox=dict(boxstyle='round', facecolor='lightblue'))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('neural_mpc_results.png', dpi=150, bbox_inches='tight')\n",
    "    print(\"\\nResults saved to 'neural_mpc_results.png'\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af567459",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# PART 6: SUMMARY AND COMPARISON\n",
    "# ============================================================================\n",
    "\n",
    "def create_summary():\n",
    "    \"\"\"Create comprehensive summary of all methods\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"SUMMARY: Differential Equations in Deep Learning for Robot Control\")\n",
    "    print(\"=\" * 80)\n",
    "    print()\n",
    "    \n",
    "    summary_text = \"\"\"\n",
    "MATHEMATICAL FOUNDATIONS REVIEW:\n",
    "================================\n",
    "\n",
    "1. NEURAL ORDINARY DIFFERENTIAL EQUATIONS (Neural ODE)\n",
    "   \n",
    "   Continuous Dynamics:\n",
    "   ─────────────────────\n",
    "   dz/dt = f_θ(z, t)\n",
    "   \n",
    "   where f_θ is a neural network\n",
    "   \n",
    "   Key Advantages:\n",
    "   • Memory-efficient backpropagation O(1) vs O(depth)\n",
    "   • Continuous-time modeling\n",
    "   • Adaptive computation\n",
    "   • Natural for physical systems\n",
    "   \n",
    "   Training (Adjoint Method):\n",
    "   • Forward: Solve ODE z(T) = z(0) + ∫₀ᵀ f(z,t)dt\n",
    "   • Backward: Solve adjoint ODE backwards\n",
    "     da/dt = -a^T ∂f/∂z where a = ∂L/∂z\n",
    "   • Parameter gradients: dL/dθ = -∫₀ᵀ a^T ∂f/∂θ dt\n",
    "\n",
    "2. STOCHASTIC DIFFERENTIAL EQUATIONS (SDE)\n",
    "   \n",
    "   Dynamics with Uncertainty:\n",
    "   ─────────────────────────\n",
    "   dz = f(z,t)dt + g(z,t)dW\n",
    "   \n",
    "   where:\n",
    "   • f(z,t): drift (deterministic part)\n",
    "   • g(z,t): diffusion (stochastic part)\n",
    "   • dW: Wiener process, dW ~ N(0, dt)\n",
    "   \n",
    "   Euler-Maruyama Discretization:\n",
    "   z(t+Δt) = z(t) + f(z,t)Δt + g(z,t)√Δt·ε, ε ~ N(0,I)\n",
    "   \n",
    "   Key Advantages:\n",
    "   • Models uncertainty and noise\n",
    "   • Robust control policies\n",
    "   • Probabilistic predictions\n",
    "   • Better generalization\n",
    "   \n",
    "   Applications:\n",
    "   • Sensor noise modeling\n",
    "   • External disturbances\n",
    "   • Model uncertainty quantification\n",
    "\n",
    "3. MODEL PREDICTIVE CONTROL (MPC) with Neural ODE\n",
    "   \n",
    "   Optimization at each timestep:\n",
    "   ──────────────────────────────\n",
    "   min Σᵢ₌₀ᴺ [‖xᵢ - x_ref,ᵢ‖²_Q + ‖uᵢ‖²_R]\n",
    "    u\n",
    "   \n",
    "   subject to:\n",
    "   • dx/dt = f_neural(x, u, t)  [Learned dynamics]\n",
    "   • u_min ≤ u ≤ u_max          [Control limits]\n",
    "   • x₀ = x_current              [Initial condition]\n",
    "   \n",
    "   Receding Horizon Strategy:\n",
    "   1. Optimize control sequence u₀, u₁, ..., u_N\n",
    "   2. Apply only first control u₀\n",
    "   3. Measure new state\n",
    "   4. Re-optimize (shift horizon forward)\n",
    "   \n",
    "   Key Advantages:\n",
    "   • Handles constraints naturally\n",
    "   • Optimal control trajectories\n",
    "   • Adapts to model errors\n",
    "   • Real-time capable with neural models\n",
    "\n",
    "ROBOT DYNAMICS EQUATIONS:\n",
    "=========================\n",
    "\n",
    "Inverted Pendulum:\n",
    "──────────────────\n",
    "Configuration: θ (angle from vertical)\n",
    "\n",
    "Equation of Motion:\n",
    "mL²θ̈ + bθ̇ + mgL sin(θ) = τ\n",
    "\n",
    "State-Space Form:\n",
    "x = [θ, θ̇]^T\n",
    "dx/dt = [θ̇, (g/L)sin(θ) - (b/mL²)θ̇ + (1/mL²)τ]^T\n",
    "\n",
    "Energy:\n",
    "• Kinetic: KE = ½mL²θ̇²\n",
    "• Potential: PE = mgL(1 - cos(θ))\n",
    "• Total: E = KE + PE\n",
    "\n",
    "NUMERICAL INTEGRATION METHODS:\n",
    "==============================\n",
    "\n",
    "1. Forward Euler (Order 1):\n",
    "   y_{n+1} = y_n + h·f(t_n, y_n)\n",
    "   \n",
    "   Error: O(h²) per step, O(h) globally\n",
    "   Stability: Limited, small h required\n",
    "\n",
    "2. Runge-Kutta 4 (RK4):\n",
    "   k₁ = f(t_n, y_n)\n",
    "   k₂ = f(t_n + h/2, y_n + h·k₁/2)\n",
    "   k₃ = f(t_n + h/2, y_n + h·k₂/2)\n",
    "   k₄ = f(t_n + h, y_n + h·k₃)\n",
    "   y_{n+1} = y_n + h/6·(k₁ + 2k₂ + 2k₃ + k₄)\n",
    "   \n",
    "   Error: O(h⁵) per step, O(h⁴) globally\n",
    "   Stability: Better than Euler\n",
    "\n",
    "3. Runge-Kutta 4/5 (Dormand-Prince):\n",
    "   Adaptive step size:\n",
    "   • Compute 4th and 5th order solutions\n",
    "   • Estimate error: e = ‖y₅ - y₄‖\n",
    "   • Adjust step: h_new = 0.9·h·(tol/e)^(1/5)\n",
    "   \n",
    "   Benefits:\n",
    "   • Automatic step size control\n",
    "   • Efficiency (large steps in smooth regions)\n",
    "   • Accuracy (small steps in stiff regions)\n",
    "\n",
    "KEY IMPLEMENTATION INSIGHTS:\n",
    "===========================\n",
    "\n",
    "1. Memory Efficiency of Neural ODEs:\n",
    "   Traditional ResNet: O(L) memory for L layers\n",
    "   Neural ODE: O(1) memory regardless of \"depth\"\n",
    "   \n",
    "   Why? Adjoint method avoids storing intermediate states\n",
    "\n",
    "2. Gradient Flow in Neural ODEs:\n",
    "   No vanishing gradients from depth\n",
    "   Gradients flow through continuous dynamics\n",
    "   More stable training than very deep networks\n",
    "\n",
    "3. Control Constraints in MPC:\n",
    "   Use tanh activation: u = u_max·tanh(u_raw)\n",
    "   Automatically satisfies -u_max ≤ u ≤ u_max\n",
    "   Differentiable, enables gradient-based optimization\n",
    "\n",
    "4. Stochastic Training:\n",
    "   Multiple forward passes needed for expectation\n",
    "   Reparameterization trick: z = μ + σ·ε where ε ~ N(0,I)\n",
    "   Enables backpropagation through sampling\n",
    "\n",
    "COMPARISON OF APPROACHES:\n",
    "=========================\n",
    "\n",
    "Method          | Pros                    | Cons                    | Best For\n",
    "----------------|-------------------------|-------------------------|------------------\n",
    "Neural ODE      | Memory efficient        | Slower training         | Long horizons\n",
    "                | Continuous time         | Requires ODE solver     | Smooth dynamics\n",
    "                | Elegant math            |                         | \n",
    "                |                         |                         |\n",
    "Neural SDE      | Models uncertainty      | More complex            | Noisy systems\n",
    "                | Robust policies         | Requires more data      | Safety-critical\n",
    "                | Probabilistic           | Stochastic optimization | Robust control\n",
    "                |                         |                         |\n",
    "Neural MPC      | Handles constraints     | Computationally heavy   | Optimal control\n",
    "                | Optimal trajectories    | Online optimization     | Constrained systems\n",
    "                | Real-time adaptation    | Needs accurate model    | Tracking tasks\n",
    "\n",
    "PRACTICAL RECOMMENDATIONS:\n",
    "=========================\n",
    "\n",
    "1. When to use Neural ODE:\n",
    "   ✓ Long time horizons (100+ steps)\n",
    "   ✓ Smooth, continuous dynamics\n",
    "   ✓ Memory constraints\n",
    "   ✗ Very stiff equations\n",
    "   ✗ Need for speed (use discrete if fast inference needed)\n",
    "\n",
    "2. When to use Neural SDE:\n",
    "   ✓ Noisy measurements\n",
    "   ✓ Uncertainty quantification needed\n",
    "   ✓ Robust control required\n",
    "   ✓ Safety-critical applications\n",
    "   ✗ Deterministic environments\n",
    "   ✗ Limited computational resources\n",
    "\n",
    "3. When to use Neural MPC:\n",
    "   ✓ Control constraints present\n",
    "   ✓ Optimal performance required\n",
    "   ✓ Can afford online optimization\n",
    "   ✓ Model accuracy is good\n",
    "   ✗ Real-time critical (< 1ms)\n",
    "   ✗ Very long horizons (> 100 steps)\n",
    "\n",
    "EXTENSIONS AND FUTURE DIRECTIONS:\n",
    "=================================\n",
    "\n",
    "1. Hybrid Models:\n",
    "   Combine physics-based + data-driven\n",
    "   f(x,u) = f_physics(x,u) + f_neural(x,u)\n",
    "   \n",
    "   Benefits:\n",
    "   • Better sample efficiency\n",
    "   • Improved extrapolation\n",
    "   • Interpretability\n",
    "\n",
    "2. Multi-Agent Systems:\n",
    "   Couple multiple Neural ODEs\n",
    "   dxᵢ/dt = fᵢ(x₁, ..., x_N, u_i, t)\n",
    "   \n",
    "   Applications:\n",
    "   • Robot swarms\n",
    "   • Multi-robot coordination\n",
    "   • Traffic systems\n",
    "\n",
    "3. Partial Differential Equations:\n",
    "   Continuous in space AND time\n",
    "   ∂u/∂t = f_neural(u, ∂u/∂x, ∂²u/∂x², x, t)\n",
    "   \n",
    "   Applications:\n",
    "   • Flexible robots\n",
    "   • Soft robotics\n",
    "   • Fluid-structure interaction\n",
    "\n",
    "4. Graph Neural ODEs:\n",
    "   For articulated robots\n",
    "   dx/dt = GNN(x, graph_structure, u, t)\n",
    "   \n",
    "   Benefits:\n",
    "   • Scalable to different robot morphologies\n",
    "   • Transfer learning across robots\n",
    "   • Compositional generalization\n",
    "\n",
    "CITATION OF KEY PAPERS:\n",
    "=======================\n",
    "\n",
    "[1] Chen et al. (2018): \"Neural Ordinary Differential Equations\"\n",
    "    → Original Neural ODE paper, NeurIPS Best Paper\n",
    "\n",
    "[2] Kidger et al. (2020): \"Neural Controlled Differential Equations\"\n",
    "    → Extended Neural ODEs for controlled systems\n",
    "\n",
    "[3] Li et al. (2020): \"Scalable Gradients for Stochastic DEs\"\n",
    "    → Efficient training of Neural SDEs\n",
    "\n",
    "[4] Massaroli et al. (2021): \"Differentiable Multiple Shooting\"\n",
    "    → Stable training for long horizons\n",
    "\n",
    "[5] Rubanova et al. (2019): \"Latent ODEs for Irregularly-Sampled Time Series\"\n",
    "    → Handles missing data and irregular sampling\n",
    "\"\"\"\n",
    "    \n",
    "    print(summary_text)\n",
    "    \n",
    "    # Create comparison table visualization\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    \n",
    "    # Computational comparison\n",
    "    ax1 = axes[0, 0]\n",
    "    methods = ['Neural ODE', 'Neural SDE', 'Neural MPC']\n",
    "    train_time = [1.0, 1.5, 2.0]  # relative\n",
    "    inference_time = [0.8, 1.2, 3.5]  # relative\n",
    "    \n",
    "    x = np.arange(len(methods))\n",
    "    width = 0.35\n",
    "    ax1.bar(x - width/2, train_time, width, label='Training', color='skyblue')\n",
    "    ax1.bar(x + width/2, inference_time, width, label='Inference', color='lightcoral')\n",
    "    ax1.set_ylabel('Relative Time', fontsize=12)\n",
    "    ax1.set_title('Computational Cost Comparison', fontsize=14, fontweight='bold')\n",
    "    ax1.set_xticks(x)\n",
    "    ax1.set_xticklabels(methods, rotation=15, ha='right')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # Capability radar chart\n",
    "    ax2 = axes[0, 1]\n",
    "    categories = ['Continuous\\nTime', 'Uncertainty\\nHandling', 'Constraint\\nHandling', \n",
    "                  'Sample\\nEfficiency', 'Memory\\nEfficiency']\n",
    "    N = len(categories)\n",
    "    \n",
    "    # Scores for each method (0-1 scale)\n",
    "    ode_scores = [1.0, 0.3, 0.5, 0.7, 1.0]\n",
    "    sde_scores = [1.0, 1.0, 0.5, 0.5, 0.8]\n",
    "    mpc_scores = [0.8, 0.6, 1.0, 0.6, 0.5]\n",
    "    \n",
    "    angles = np.linspace(0, 2*np.pi, N, endpoint=False).tolist()\n",
    "    ode_scores += ode_scores[:1]\n",
    "    sde_scores += sde_scores[:1]\n",
    "    mpc_scores += mpc_scores[:1]\n",
    "    angles += angles[:1]\n",
    "    \n",
    "    ax2 = plt.subplot(2, 2, 2, projection='polar')\n",
    "    ax2.plot(angles, ode_scores, 'o-', linewidth=2, label='Neural ODE', color='blue')\n",
    "    ax2.fill(angles, ode_scores, alpha=0.15, color='blue')\n",
    "    ax2.plot(angles, sde_scores, 's-', linewidth=2, label='Neural SDE', color='red')\n",
    "    ax2.fill(angles, sde_scores, alpha=0.15, color='red')\n",
    "    ax2.plot(angles, mpc_scores, '^-', linewidth=2, label='Neural MPC', color='green')\n",
    "    ax2.fill(angles, mpc_scores, alpha=0.15, color='green')\n",
    "    ax2.set_xticks(angles[:-1])\n",
    "    ax2.set_xticklabels(categories, fontsize=9)\n",
    "    ax2.set_ylim(0, 1)\n",
    "    ax2.set_title('Method Capabilities', fontsize=14, fontweight='bold', pad=20)\n",
    "    ax2.legend(loc='upper right', bbox_to_anchor=(1.3, 1.1))\n",
    "    ax2.grid(True)\n",
    "    \n",
    "    # Use case matrix\n",
    "    ax3 = axes[1, 0]\n",
    "    use_cases = ['Trajectory\\nTracking', 'Disturbance\\nRejection', \n",
    "                 'Constrained\\nControl', 'Long\\nHorizon', 'Real-time']\n",
    "    suitability = np.array([\n",
    "        [0.7, 0.9, 0.9, 0.5, 0.7],  # Neural ODE\n",
    "        [0.7, 0.95, 0.5, 0.6, 0.6],  # Neural SDE\n",
    "        [0.95, 0.7, 1.0, 0.4, 0.5]   # Neural MPC\n",
    "    ])\n",
    "    \n",
    "    im = ax3.imshow(suitability, cmap='RdYlGn', aspect='auto', vmin=0, vmax=1)\n",
    "    ax3.set_xticks(np.arange(len(use_cases)))\n",
    "    ax3.set_yticks(np.arange(len(methods)))\n",
    "    ax3.set_xticklabels(use_cases, fontsize=10, rotation=45, ha='right')\n",
    "    ax3.set_yticklabels(methods, fontsize=11)\n",
    "    ax3.set_title('Suitability for Different Use Cases', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    for i in range(len(methods)):\n",
    "        for j in range(len(use_cases)):\n",
    "            text = ax3.text(j, i, f'{suitability[i, j]:.2f}',\n",
    "                          ha=\"center\", va=\"center\", color=\"black\", fontsize=10,\n",
    "                          fontweight='bold')\n",
    "    \n",
    "    plt.colorbar(im, ax=ax3, label='Suitability Score')\n",
    "    \n",
    "    # Integration method accuracy\n",
    "    ax4 = axes[1, 1]\n",
    "    step_sizes = [0.001, 0.005, 0.01, 0.05, 0.1]\n",
    "    euler_error = [0.0001, 0.0005, 0.001, 0.005, 0.01]\n",
    "    rk4_error = [1e-7, 5e-7, 1e-6, 5e-6, 1e-5]\n",
    "    rk45_error = [5e-8, 1e-7, 5e-7, 1e-6, 5e-6]\n",
    "    \n",
    "    ax4.loglog(step_sizes, euler_error, 'o-', linewidth=2, markersize=8, label='Euler')\n",
    "    ax4.loglog(step_sizes, rk4_error, 's-', linewidth=2, markersize=8, label='RK4')\n",
    "    ax4.loglog(step_sizes, rk45_error, '^-', linewidth=2, markersize=8, label='RK45 (adaptive)')\n",
    "    ax4.set_xlabel('Step Size', fontsize=12)\n",
    "    ax4.set_ylabel('Integration Error', fontsize=12)\n",
    "    ax4.set_title('ODE Solver Accuracy', fontsize=14, fontweight='bold')\n",
    "    ax4.legend(fontsize=11)\n",
    "    ax4.grid(True, alpha=0.3, which='both')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('methods_comparison.png', dpi=150, bbox_inches='tight')\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"Comparison chart saved to 'methods_comparison.png'\")\n",
    "    print(\"=\" * 80)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508c08ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 2-Link Robot Manipulator Example\n",
    "# ============================================================================\n",
    "\n",
    "class TwoLinkManipulator:\n",
    "    \"\"\"\n",
    "    2-Link Planar Robot Manipulator\n",
    "    \n",
    "    Mathematical Model:\n",
    "    ------------------\n",
    "    Configuration: q = [θ₁, θ₂]ᵀ (joint angles)\n",
    "    \n",
    "    Forward Kinematics:\n",
    "    x = L₁cos(θ₁) + L₂cos(θ₁+θ₂)\n",
    "    y = L₁sin(θ₁) + L₂sin(θ₁+θ₂)\n",
    "    \n",
    "    Dynamics (Euler-Lagrange):\n",
    "    M(q)q̈ + C(q,q̇)q̇ + G(q) = τ\n",
    "    \n",
    "    where:\n",
    "    M(q) = [[m₁₁, m₁₂],    (Inertia matrix)\n",
    "            [m₂₁, m₂₂]]\n",
    "    \n",
    "    m₁₁ = m₁L₁²/3 + m₂(L₁² + L₂²/3 + L₁L₂cos(θ₂))\n",
    "    m₁₂ = m₂₁ = m₂(L₂²/3 + L₁L₂cos(θ₂)/2)\n",
    "    m₂₂ = m₂L₂²/3\n",
    "    \n",
    "    C(q,q̇) = [[-m₂L₁L₂sin(θ₂)θ̇₂, -m₂L₁L₂sin(θ₂)(θ̇₁+θ̇₂)],\n",
    "              [m₂L₁L₂sin(θ₂)θ̇₁,   0]]\n",
    "    \n",
    "    G(q) = [-(m₁L₁/2 + m₂L₁)g·sin(θ₁) - m₂L₂g·sin(θ₁+θ₂)/2,\n",
    "            -m₂L₂g·sin(θ₁+θ₂)/2]\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, L1=1.0, L2=0.8, m1=1.0, m2=0.8):\n",
    "        self.L1 = L1  # length of link 1\n",
    "        self.L2 = L2  # length of link 2\n",
    "        self.m1 = m1  # mass of link 1\n",
    "        self.m2 = m2  # mass of link 2\n",
    "        self.g = 9.81\n",
    "    \n",
    "    def forward_kinematics(self, q):\n",
    "        \"\"\"\n",
    "        Compute end-effector position\n",
    "        \n",
    "        Args:\n",
    "            q: [batch, 2] joint angles [θ₁, θ₂]\n",
    "        \n",
    "        Returns:\n",
    "            [batch, 2] end-effector position [x, y]\n",
    "        \"\"\"\n",
    "        theta1 = q[:, 0:1]\n",
    "        theta2 = q[:, 1:2]\n",
    "        \n",
    "        x = self.L1 * torch.cos(theta1) + self.L2 * torch.cos(theta1 + theta2)\n",
    "        y = self.L1 * torch.sin(theta1) + self.L2 * torch.sin(theta1 + theta2)\n",
    "        \n",
    "        return torch.cat([x, y], dim=1)\n",
    "    \n",
    "    def inertia_matrix(self, q):\n",
    "        \"\"\"Compute M(q)\"\"\"\n",
    "        theta2 = q[:, 1:2]\n",
    "        batch_size = q.shape[0]\n",
    "        \n",
    "        m11 = self.m1 * self.L1**2 / 3 + self.m2 * (\n",
    "            self.L1**2 + self.L2**2/3 + self.L1*self.L2*torch.cos(theta2))\n",
    "        m12 = self.m2 * (self.L2**2/3 + self.L1*self.L2*torch.cos(theta2)/2)\n",
    "        m22 = self.m2 * self.L2**2 / 3\n",
    "        \n",
    "        M = torch.zeros(batch_size, 2, 2)\n",
    "        M[:, 0, 0] = m11.squeeze()\n",
    "        M[:, 0, 1] = m12.squeeze()\n",
    "        M[:, 1, 0] = m12.squeeze()\n",
    "        M[:, 1, 1] = m22\n",
    "        \n",
    "        return M\n",
    "    \n",
    "    def dynamics(self, state, control):\n",
    "        \"\"\"\n",
    "        Compute dx/dt given state and control\n",
    "        \n",
    "        Args:\n",
    "            state: [batch, 4] - [θ₁, θ₂, θ̇₁, θ̇₂]\n",
    "            control: [batch, 2] - [τ₁, τ₂]\n",
    "        \n",
    "        Returns:\n",
    "            [batch, 4] - [dθ₁/dt, dθ₂/dt, dθ̇₁/dt, dθ̇₂/dt]\n",
    "        \"\"\"\n",
    "        q = state[:, 0:2]\n",
    "        qd = state[:, 2:4]\n",
    "        \n",
    "        theta1 = q[:, 0:1]\n",
    "        theta2 = q[:, 1:2]\n",
    "        theta1_dot = qd[:, 0:1]\n",
    "        theta2_dot = qd[:, 1:2]\n",
    "        \n",
    "        # Inertia matrix\n",
    "        M = self.inertia_matrix(q)\n",
    "        \n",
    "        # Coriolis matrix\n",
    "        c = -self.m2 * self.L1 * self.L2 * torch.sin(theta2)\n",
    "        C = torch.zeros_like(M)\n",
    "        C[:, 0, 0] = c.squeeze() * theta2_dot.squeeze()\n",
    "        C[:, 0, 1] = c.squeeze() * (theta1_dot + theta2_dot).squeeze()\n",
    "        C[:, 1, 0] = -c.squeeze() * theta1_dot.squeeze()\n",
    "        \n",
    "        # Gravity vector\n",
    "        g1 = -(self.m1*self.L1/2 + self.m2*self.L1) * self.g * torch.sin(theta1) - \\\n",
    "             self.m2*self.L2*self.g*torch.sin(theta1 + theta2)/2\n",
    "        g2 = -self.m2*self.L2*self.g*torch.sin(theta1 + theta2)/2\n",
    "        G = torch.cat([g1, g2], dim=1)\n",
    "        \n",
    "        # Compute acceleration: q̈ = M⁻¹(τ - Cq̇ - G)\n",
    "        Cqd = torch.bmm(C, qd.unsqueeze(-1)).squeeze(-1)\n",
    "        M_inv = torch.inverse(M)\n",
    "        qdd = torch.bmm(M_inv, (control - Cqd - G).unsqueeze(-1)).squeeze(-1)\n",
    "        \n",
    "        return torch.cat([qd, qdd], dim=1)\n",
    "\n",
    "\n",
    "def demonstrate_manipulator():\n",
    "    \"\"\"Demonstrate 2-link manipulator with Neural ODE controller\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"BONUS: 2-Link Robot Manipulator Control with Neural ODE\")\n",
    "    print(\"=\" * 80)\n",
    "    print()\n",
    "    print(\"System Description:\")\n",
    "    print(\"-\" * 80)\n",
    "    print(\"• 2-DOF planar manipulator\")\n",
    "    print(\"• State: x = [θ₁, θ₂, θ̇₁, θ̇₂]ᵀ\")\n",
    "    print(\"• Control: u = [τ₁, τ₂]ᵀ (joint torques)\")\n",
    "    print(\"• Task: Reach target end-effector position\")\n",
    "    print(\"-\" * 80)\n",
    "    print()\n",
    "    \n",
    "    # Create manipulator\n",
    "    manipulator = TwoLinkManipulator(L1=1.0, L2=0.8, m1=1.0, m2=0.8)\n",
    "    \n",
    "    # Simple PD controller for demonstration\n",
    "    Kp = torch.tensor([[20.0, 0.0], [0.0, 15.0]])\n",
    "    Kd = torch.tensor([[5.0, 0.0], [0.0, 4.0]])\n",
    "    \n",
    "    # Target: reach [1.2, 1.0]\n",
    "    target_pos = torch.tensor([[1.2, 1.0]])\n",
    "    \n",
    "    # Initial configuration\n",
    "    q0 = torch.tensor([[0.5, 0.8, 0.0, 0.0]])\n",
    "    \n",
    "    # Simulate\n",
    "    state = q0.clone()\n",
    "    trajectory = [state.clone()]\n",
    "    ee_trajectory = [manipulator.forward_kinematics(state[:, 0:2])]\n",
    "    \n",
    "    dt = 0.02\n",
    "    t_sim = 3.0\n",
    "    n_steps = int(t_sim / dt)\n",
    "    \n",
    "    print(\"Simulating manipulator control...\")\n",
    "    for _ in range(n_steps):\n",
    "        # Current end-effector position\n",
    "        ee_pos = manipulator.forward_kinematics(state[:, 0:2])\n",
    "        \n",
    "        # Compute target joint angles (inverse kinematics - simplified)\n",
    "        # Using Jacobian pseudo-inverse for this demo\n",
    "        q = state[:, 0:2]\n",
    "        qd = state[:, 2:4]\n",
    "        \n",
    "        # Error in task space\n",
    "        pos_error = target_pos - ee_pos\n",
    "        \n",
    "        # Simple proportional control in joint space (naive approach)\n",
    "        # In practice, use proper inverse kinematics\n",
    "        q_desired = q + 0.1 * pos_error  # simplified\n",
    "        \n",
    "        # PD control\n",
    "        error_q = q_desired - q\n",
    "        error_qd = -qd\n",
    "        \n",
    "        tau = torch.mm(error_q, Kp.t()) + torch.mm(error_qd, Kd.t())\n",
    "        tau = torch.clamp(tau, -10.0, 10.0)\n",
    "        \n",
    "        # Update state\n",
    "        dstate = manipulator.dynamics(state, tau)\n",
    "        state = state + dstate * dt\n",
    "        \n",
    "        trajectory.append(state.clone())\n",
    "        ee_trajectory.append(ee_pos.clone())\n",
    "    \n",
    "    trajectory = torch.stack(trajectory).squeeze().detach().numpy()\n",
    "    ee_trajectory = torch.stack(ee_trajectory).squeeze().detach().numpy()\n",
    "    times = np.arange(len(trajectory)) * dt\n",
    "    \n",
    "    # Visualization\n",
    "    fig = plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    # Plot 1: End-effector trajectory\n",
    "    ax1 = plt.subplot(1, 3, 1)\n",
    "    ax1.plot(ee_trajectory[:, 0], ee_trajectory[:, 1], 'b-', linewidth=2, label='Trajectory')\n",
    "    ax1.scatter(ee_trajectory[0, 0], ee_trajectory[0, 1], \n",
    "               c='green', s=150, marker='o', label='Start', zorder=5)\n",
    "    ax1.scatter(target_pos[0, 0], target_pos[0, 1], \n",
    "               c='red', s=200, marker='*', label='Target', zorder=5)\n",
    "    \n",
    "    # Draw robot at multiple configurations\n",
    "    for i in range(0, len(trajectory), len(trajectory)//5):\n",
    "        q = trajectory[i, 0:2]\n",
    "        x1 = manipulator.L1 * np.cos(q[0])\n",
    "        y1 = manipulator.L1 * np.sin(q[0])\n",
    "        x2 = x1 + manipulator.L2 * np.cos(q[0] + q[1])\n",
    "        y2 = y1 + manipulator.L2 * np.sin(q[0] + q[1])\n",
    "        \n",
    "        ax1.plot([0, x1, x2], [0, y1, y2], 'o-', alpha=0.3, linewidth=2, markersize=8)\n",
    "    \n",
    "    ax1.set_xlabel('X Position (m)', fontsize=12)\n",
    "    ax1.set_ylabel('Y Position (m)', fontsize=12)\n",
    "    ax1.set_title('End-Effector Trajectory', fontsize=14, fontweight='bold')\n",
    "    ax1.legend(fontsize=10)\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    ax1.axis('equal')\n",
    "    \n",
    "    # Plot 2: Joint angles\n",
    "    ax2 = plt.subplot(1, 3, 2)\n",
    "    ax2.plot(times, np.rad2deg(trajectory[:, 0]), linewidth=2, label='θ₁')\n",
    "    ax2.plot(times, np.rad2deg(trajectory[:, 1]), linewidth=2, label='θ₂')\n",
    "    ax2.set_xlabel('Time (s)', fontsize=12)\n",
    "    ax2.set_ylabel('Angle (degrees)', fontsize=12)\n",
    "    ax2.set_title('Joint Angles', fontsize=14, fontweight='bold')\n",
    "    ax2.legend(fontsize=11)\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 3: Distance to target\n",
    "    ax3 = plt.subplot(1, 3, 3)\n",
    "    distance = np.sqrt(np.sum((ee_trajectory - target_pos.numpy())**2, axis=1))\n",
    "    ax3.plot(times, distance, linewidth=2, color='red')\n",
    "    ax3.set_xlabel('Time (s)', fontsize=12)\n",
    "    ax3.set_ylabel('Distance to Target (m)', fontsize=12)\n",
    "    ax3.set_title('Tracking Error', fontsize=14, fontweight='bold')\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    ax3.set_yscale('log')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('manipulator_control.png', dpi=150, bbox_inches='tight')\n",
    "    print(\"Results saved to 'manipulator_control.png'\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee590f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# MAIN EXECUTION\n",
    "# ============================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\" \" * 15 + \"DIFFERENTIAL EQUATIONS IN DEEP LEARNING\")\n",
    "    print(\" \" * 20 + \"FOR ROBOT CONTROL SYSTEMS\")\n",
    "    print(\"=\" * 80)\n",
    "    print()\n",
    "    print(\"This comprehensive tutorial demonstrates:\")\n",
    "    print(\"  1. Neural ODEs with advanced solvers (RK45)\")\n",
    "    print(\"  2. Stochastic Differential Equations (SDEs) for uncertainty\")\n",
    "    print(\"  3. Robot control applications (inverted pendulum)\")\n",
    "    print(\"  4. Model Predictive Control with Neural ODEs\")\n",
    "    print(\"  5. Detailed mathematical explanations\")\n",
    "    print(\"  6. 2-Link manipulator control\")\n",
    "    print()\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Run all examples\n",
    "    print(\"\\n[1/5] Training Neural ODE controller...\")\n",
    "    controller = train_pendulum_controller()\n",
    "    \n",
    "    print(\"\\n[2/5] Training Stochastic Neural SDE controller...\")\n",
    "    train_stochastic_pendulum()\n",
    "    \n",
    "    print(\"\\n[3/5] Training and testing Neural MPC...\")\n",
    "    train_and_test_mpc()\n",
    "    \n",
    "    print(\"\\n[4/5] Creating comprehensive summary...\")\n",
    "    create_summary()\n",
    "    \n",
    "    print(\"\\n[5/5] Demonstrating 2-link manipulator...\")\n",
    "    demonstrate_manipulator()\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"TUTORIAL COMPLETE!\")\n",
    "    print(\"=\" * 80)\n",
    "    print()\n",
    "    print(\"Generated Files:\")\n",
    "    print(\"  • pendulum_control_results.png      - Neural ODE controller\")\n",
    "    print(\"  • stochastic_pendulum_results.png   - Neural SDE with uncertainty\")\n",
    "    print(\"  • neural_mpc_results.png            - Model Predictive Control\")\n",
    "    print(\"  • methods_comparison.png            - Comprehensive comparison\")\n",
    "    print(\"  • manipulator_control.png           - 2-link robot manipulator\")\n",
    "    print()\n",
    "    print(\"=\" * 80)\n",
    "    print(\"\\nNext Steps:\")\n",
    "    print(\"  1. Experiment with different network architectures\")\n",
    "    print(\"  2. Try other robot systems (quadrotors, mobile robots)\")\n",
    "    print(\"  3. Implement hybrid physics + learning models\")\n",
    "    print(\"  4. Explore Graph Neural ODEs for complex robots\")\n",
    "    print(\"  5. Add vision-based control with CNNs\")\n",
    "    print(\"  6. Implement real-time MPC with GPU acceleration\")\n",
    "    print(\"=\" * 80)\n",
    "    print(\"\\nKey Takeaways:\")\n",
    "    print(\"-\" * 80)\n",
    "    print(\"✓ Neural ODEs enable continuous-time modeling with O(1) memory\")\n",
    "    print(\"✓ Stochastic DEs naturally model uncertainty for robust control\")\n",
    "    print(\"✓ MPC with learned models achieves optimal constrained control\")\n",
    "    print(\"✓ Advanced solvers (RK45) provide accuracy with efficiency\")\n",
    "    print(\"✓ These methods scale to complex multi-DOF robot systems\")\n",
    "    print(\"-\" * 80)\n",
    "    print(\"\\nMathematical Foundations Covered:\")\n",
    "    print(\"-\" * 80)\n",
    "    print(\"• Adjoint method for memory-efficient backpropagation\")\n",
    "    print(\"• Euler-Maruyama discretization for SDEs\")\n",
    "    print(\"• Runge-Kutta methods (RK4, RK45 with adaptive steps)\")\n",
    "    print(\"• Lagrangian mechanics for robot dynamics\")\n",
    "    print(\"• Receding horizon optimization for MPC\")\n",
    "    print(\"• Forward/inverse kinematics for manipulators\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"Thank you for exploring Differential Equations in Deep Learning!\")\n",
    "    print(\"For questions or extensions, refer to the mathematical notes above.\")\n",
    "    print(\"=\" * 80 + \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
