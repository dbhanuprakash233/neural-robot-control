# Neural Control Systems for Robotics

Advanced robot control using Neural ODEs, Stochastic Differential Equations, and Model Predictive Control with learned dynamics models.

## ğŸ¤– Overview

This project demonstrates state-of-the-art control techniques for robotic systems:

1. **Neural ODE Control** - Continuous-time policies for smooth control
2. **Stochastic Robust Control** - Handling uncertainty and disturbances
3. **Neural MPC** - Optimal control with learned dynamics
4. **Multi-DOF Systems** - Scaling to complex robots

## ğŸ¯ Robot Systems

### 1. Inverted Pendulum
- **DOF**: 1 (rotation)
- **State**: [Î¸, Î¸Ì‡] (angle, angular velocity)
- **Control**: Ï„ (torque)
- **Challenge**: Unstable equilibrium at upright position

### 2. 2-Link Planar Manipulator
- **DOF**: 2 (shoulder, elbow)
- **State**: [Î¸â‚, Î¸â‚‚, Î¸Ì‡â‚, Î¸Ì‡â‚‚]
- **Control**: [Ï„â‚, Ï„â‚‚] (joint torques)
- **Challenge**: Coupled nonlinear dynamics

## ğŸš€ Features

- âœ… Physics-based robot models (Lagrangian mechanics)
- âœ… Neural ODE controllers with RK45 integration
- âœ… Stochastic control for robustness
- âœ… Model Predictive Control with constraints
- âœ… Real-time visualization
- âœ… Performance comparison framework

## ğŸ“¦ Installation

```bash
pip install -r requirements.txt
```

## ğŸ“ Usage

### Experiment 1: Neural ODE Pendulum Control

**What it does**: Train Neural ODE controller to balance inverted pendulum

**Expected Output**:
- `pendulum_control_results.png`
  - Training progress
  - Angle trajectory (converges to 0Â°)
  - Control input
  - Phase portrait
  - Energy analysis

**Key Insights**:
- Neural ODE learns smooth control policies
- Energy decreases as pendulum stabilizes
- Control input bounded and efficient

---

### Experiment 2: Stochastic Robust Control

**What it does**: Handle uncertainty and noise in pendulum control

**Expected Output**:
- `stochastic_pendulum_results.png`
  - 20 stochastic rollouts showing uncertainty
  - Mean trajectory with confidence bounds
  - Learned noise scale over training
  - Uncertainty evolution over time

**Key Insights**:
- SDE models naturally handle noise
- Multiple rollouts quantify uncertainty
- Policy learns optimal noise tolerance

---

### Experiment 3: Model Predictive Control

**What it does**: Track reference trajectory with optimal control

**Expected Output**:
- `neural_mpc_results.png`
  - Tracking performance (actual vs reference)
  - Tracking error (RMS)
  - Control input (respects constraints)
  - Computation time per step
  - Control effort analysis

**Key Insights**:
- MPC optimizes over prediction horizon
- Learns dynamics from data
- Real-time capable (~10-50ms per step)
- Handles constraints naturally

---

### Experiment 4: 2-Link Manipulator

**What it does**: Control 2-DOF robot arm to reach targets

**Expected Output**:
- `manipulator_control.png`
  - End-effector trajectory in workspace
  - Multiple robot configurations
  - Joint angles over time
  - Distance to target (log scale)

**Key Insights**:
- Extends to multi-DOF systems
- Coupled nonlinear dynamics
- Forward kinematics for task space

---

### Method Comparison

**What it does**: Comprehensive comparison of all methods

**Expected Output**:
- `methods_comparison.png` with 4 subplots:
  1. Computational cost (training vs inference)
  2. Capability radar chart
  3. Use case suitability matrix
  4. ODE solver accuracy comparison

---

## ğŸ® Robot Dynamics

### Inverted Pendulum

**Equation of Motion**:
```
mLÂ²Î¸Ìˆ + bÎ¸Ì‡ + mgLÂ·sin(Î¸) = Ï„
```

**State Space**:
```
dx/dt = [Î¸Ì‡, (g/L)sin(Î¸) - (b/mLÂ²)Î¸Ì‡ + (1/mLÂ²)Ï„]áµ€
```

**Parameters**:
- m = 1.0 kg (mass)
- L = 1.0 m (length)
- b = 0.1 (damping)
- g = 9.81 m/sÂ²

---

### 2-Link Manipulator

**Dynamics** (Euler-Lagrange):
```
M(q)qÌˆ + C(q,qÌ‡)qÌ‡ + G(q) = Ï„
```

**Inertia Matrix**:
```
M(q) = [[mâ‚â‚, mâ‚â‚‚],
        [mâ‚â‚‚, mâ‚‚â‚‚]]

mâ‚â‚ = mâ‚Lâ‚Â²/3 + mâ‚‚(Lâ‚Â² + Lâ‚‚Â²/3 + Lâ‚Lâ‚‚cos(Î¸â‚‚))
mâ‚â‚‚ = mâ‚‚(Lâ‚‚Â²/3 + Lâ‚Lâ‚‚cos(Î¸â‚‚)/2)
mâ‚‚â‚‚ = mâ‚‚Lâ‚‚Â²/3
```

**Forward Kinematics**:
```
x = Lâ‚cos(Î¸â‚) + Lâ‚‚cos(Î¸â‚+Î¸â‚‚)
y = Lâ‚sin(Î¸â‚) + Lâ‚‚sin(Î¸â‚+Î¸â‚‚)
```

---

## ğŸ“Š Performance Metrics

| Controller | Settling Time | RMS Error | Control Effort | Computation |
|------------|---------------|-----------|----------------|-------------|
| Neural ODE | 3-5 sec | 2-5Â° | Moderate | Fast (~1ms) |
| Stochastic | 4-6 sec | 3-7Â° | Moderate | Fast (~2ms) |
| Neural MPC | 2-4 sec | 1-3Â° | Optimal | Slow (~20ms) |

## ğŸ¯ Method Selection Guide

### Use Neural ODE When:
âœ… Smooth, continuous control needed  
âœ… Long time horizons (>5 seconds)  
âœ… Memory efficiency matters  
âœ… Real-time performance critical

### Use Stochastic Control When:
âœ… Environment has significant noise  
âœ… Uncertainty quantification needed  
âœ… Safety-critical applications  
âœ… Robustness is priority

### Use Neural MPC When:
âœ… Optimal performance required  
âœ… Hard constraints present  
âœ… Can afford computation time  
âœ… Accurate model available

## ğŸ”¬ Advanced Topics

### 1. Hybrid Models
Combine physics + learning:
```python
f_total(x,u) = f_physics(x,u) + f_neural(x,u)
```

**Benefits**:
- Better sample efficiency
- Improved extrapolation
- Physical interpretability

### 2. Real-time Implementation
```python
# GPU acceleration
model = model.cuda()
state = state.cuda()

# JIT compilation
model = torch.jit.script(model)
```

### 3. Vision-based Control
```python
class VisualController(nn.Module):
    def __init__(self):
        self.cnn = CNN()  # Image encoder
        self.ode = NeuralODE()  # Dynamics
        self.policy = Policy()  # Controller
```

## ğŸš Extension: Quadrotor Control

**Coming Soon**: 6-DOF quadrotor with:
- Position control (x, y, z)
- Attitude control (roll, pitch, yaw)
- Neural MPC for trajectory tracking
- Obstacle avoidance


## ğŸ“ˆ Benchmarks

### Inverted Pendulum
- **Success Rate**: 95%+ (starting from Â±90Â°)
- **Stabilization**: < 5 seconds
- **Energy Efficiency**: 30% better than PID

### 2-Link Manipulator
- **Reaching Accuracy**: Â±2 cm
- **Trajectory Tracking**: RMS error < 3 cm
- **Computation**: Real-time on CPU

## ğŸ¯ Quick Start Commands

```bash
# Setup
git clone https://github.com/dbhanuprakash233/neural-robot-control.git 

cd neural-robot-control

# Install dependencies
pip install -r requirements.txt

# Launch Jupyter
jupyter lab

# Open notebook:
Neural-Robot-Control.ipynb
```

## ğŸ“¸ Expected Outputs

- âœ… 5 PNG files showing robot control results
- âœ… Performance metrics and comparisons
- âœ… Real-world applicable control systems

## ğŸ¤ Contributing

Areas for contribution:
- Additional robot models (quadrotor, mobile robot)
- Real hardware integration (ROS, PyBullet)
- Vision-based control
- Multi-agent coordination

## ğŸ“š References

1. Chen et al. (2018): "Neural ODEs" - Continuous control
2. Greydanus et al. (2019): "Hamiltonian Neural Networks"
3. Lutter et al. (2019): "Deep Lagrangian Networks"
4. Bansal et al. (2021): "DeepReach" - Safety verification

## ğŸ“§ Contact

ğŸ“§ **Email**: [dbhanuprakash233@gmail.com](mailto:dbhanuprakash233@gmail.com)  
ğŸ™ **GitHub**: [@dbhanuprakash233](https://github.com/dbhanuprakash233)

---